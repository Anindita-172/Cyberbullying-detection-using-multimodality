{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haiHIIElmD3P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MWdvfTtmMzV"
      },
      "outputs": [],
      "source": [
        "# !pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IW9gl9KoFKH"
      },
      "outputs": [],
      "source": [
        "# !pip install SpeechRecognition pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dJ8320V6mXF_",
        "outputId": "7f29e660-827d-40ab-cfad-b410fc003631"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                         tweet_text  type  \\\n",
              "0           0                        in words food crapilicious   none   \n",
              "1           2               classy whore or red velvet cupcakes   none   \n",
              "2           3  meh thanks heads up concerned angry dude twitter   none   \n",
              "3           4  this isis account pretending kurdish account l...  none   \n",
              "4           5  yes test god good bad indifferent weird whatev...  none   \n",
              "\n",
              "   text_len  \n",
              "0       4.0  \n",
              "1       6.0  \n",
              "2       8.0  \n",
              "3       9.0  \n",
              "4      11.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd2b9f92-279c-47c6-8325-2622ac2a69ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>type</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>in words food crapilicious</td>\n",
              "      <td>none</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>classy whore or red velvet cupcakes</td>\n",
              "      <td>none</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>meh thanks heads up concerned angry dude twitter</td>\n",
              "      <td>none</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>this isis account pretending kurdish account l...</td>\n",
              "      <td>none</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>yes test god good bad indifferent weird whatev...</td>\n",
              "      <td>none</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd2b9f92-279c-47c6-8325-2622ac2a69ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd2b9f92-279c-47c6-8325-2622ac2a69ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd2b9f92-279c-47c6-8325-2622ac2a69ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "rd=pd.read_csv(\"/content/EDA_PP_F.csv\",encoding='latin1')\n",
        "rd.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJaxrE2ioi6F"
      },
      "source": [
        "Baseline Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3GEYJeRoWII"
      },
      "outputs": [],
      "source": [
        "label_enc = LabelEncoder()\n",
        "rd['type'] = label_enc.fit_transform(rd['type'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToLSxBtuonOp"
      },
      "outputs": [],
      "source": [
        "X = rd['tweet_text']\n",
        "y = rd['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qajf1CCrooxR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwR_KmNWotQ4",
        "outputId": "3220b1bd-7934-4f60-b6d5-7ebb704b7092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 6300],\n",
              "       [   1, 5204],\n",
              "       [   2, 3927],\n",
              "       [   3, 6179],\n",
              "       [   4, 6331],\n",
              "       [   5, 5843]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tgc2Yq8oz-6"
      },
      "outputs": [],
      "source": [
        "\n",
        "ros = RandomOverSampler()\n",
        "X_train, y_train = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1));\n",
        "train_os = pd.DataFrame(list(zip([x[0] for x in X_train], y_train)), columns = ['tweet_text', 'type']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qei5UPsDo1ZM"
      },
      "outputs": [],
      "source": [
        "X_train = train_os['tweet_text'].values\n",
        "y_train = train_os['type'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrRLR817o3Mt",
        "outputId": "ba841ec8-2840-4d27-e086-a1b60f602a00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 6331],\n",
              "       [   1, 6331],\n",
              "       [   2, 6331],\n",
              "       [   3, 6331],\n",
              "       [   4, 6331],\n",
              "       [   5, 6331]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEes4OUBo9C9"
      },
      "source": [
        "Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMDliSVDo-YR"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()\n",
        "X_train_cv =  cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2HNabgAo_Lt"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhLPclRIpbXK"
      },
      "outputs": [],
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
        "X_train_tf = tf_transformer.transform(X_train_cv)\n",
        "X_test_tf = tf_transformer.transform(X_test_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn1ETLy4pfhg"
      },
      "source": [
        "Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0C0y-NzpBDl"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "xgb = XGBClassifier(eval_metric=\"mlogloss\",random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "svc = SVC(random_state=42)\n",
        "nb = MultinomialNB()\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"Random Forest\": rf,\n",
        "    \"Gradient Boosting\":gb,\n",
        "    \"AdaBoost\": ada,\n",
        "    \"LightGBM\": lgb,\n",
        "    \"XGBoost\": xgb,\n",
        "    \"Decision Tree\":dt,\n",
        "    \"Support Vector Machine\":svc,\n",
        "    \"Naive Bayes\": nb,\n",
        "    \"Multilayer Perceptron\":mlp\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFcZAWfspjQJ"
      },
      "outputs": [],
      "source": [
        "def fit_model(clf,x_train,y_train,x_test, y_test):\n",
        "    clf.fit(x_train,y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "    accuracy = accuracy_score(y_pred, y_test)\n",
        "    return accuracy\n",
        "\n",
        "accuracys = []\n",
        "\n",
        "\n",
        "for name,clf in models.items():\n",
        "     curr_acc = fit_model(clf,X_train_tf,y_train,X_test_tf,y_test)\n",
        "     accuracys.append(curr_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4innglXpo6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "30bed147-299e-48fb-f5d7-df88ed50e2af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Models  Accuracy Scores\n",
              "0  Random Forest         0.854741"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b6b19cb-2b1f-4be7-adc4-d8365e41f48b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>Accuracy Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.854741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6b19cb-2b1f-4be7-adc4-d8365e41f48b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b6b19cb-2b1f-4be7-adc4-d8365e41f48b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b6b19cb-2b1f-4be7-adc4-d8365e41f48b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "models_df = pd.DataFrame({\"Models\":models.keys(),\"Accuracy Scores\":accuracys}).sort_values('Accuracy Scores',ascending=False)\n",
        "models_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7F_qgICpsKx"
      },
      "outputs": [],
      "source": [
        "sentiments = [\"age\",\"not bullying\",\"racism\",\"religion\",\"gender\"]\n",
        "all_categories_names=np.array(sentiments)\n",
        "x=rf.predict(cv.transform([\"hi hello\"]))\n",
        "print(all_categories_names[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWjOzCDrpujn"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "translator=Translator()\n",
        "translated=translator.translate(\"Alle Muslime sind Terroristen\")\n",
        "print(translated.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIL-iKespyDQ"
      },
      "outputs": [],
      "source": [
        "x=rf.predict(cv.transform([translated.text]))\n",
        "print(all_categories_names[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR6i9aH4p1sf"
      },
      "source": [
        "Audio Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLGZf_gXp0Rq"
      },
      "outputs": [],
      "source": [
        "# all imports\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  print(\"Speak Now...\")\n",
        "  display(Javascript(RECORD))\n",
        "  sec += 1\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  print(\"Done Recording !\")\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  return b #byte stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA_vE-e5p98J"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def save_audio_file(byte_stream, filename):\n",
        "    # read the byte stream into an audio segment\n",
        "    audio_segment = AudioSegment.from_file(BytesIO(byte_stream))\n",
        "\n",
        "    # set the frame rate of the audio segment\n",
        "    audio_segment = audio_segment.set_frame_rate(16000)\n",
        "\n",
        "    # export the audio segment to a file\n",
        "    audio_segment.export(filename, format=\"wav\")\n",
        "\n",
        "    print(\"Audio file saved as:\", filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFQoxm6SqAR3"
      },
      "outputs": [],
      "source": [
        "byte_stream = record(5)\n",
        "save_audio_file(byte_stream, \"my_audiofile.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVpeQ0IMqCqn"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "filename = \"/content/my_audiofile.wav\"\n",
        "# initialize the recognizer\n",
        "r = sr.Recognizer()\n",
        "# open the file\n",
        "with sr.AudioFile(filename) as source:\n",
        "    # listen for the data (load audio to memory)\n",
        "    audio_data = r.record(source)\n",
        "    # recognize (convert from speech to text)\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilLd3U5WqEUF"
      },
      "outputs": [],
      "source": [
        "x=rf.predict(cv.transform([text]))\n",
        "print(all_categories_names[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyRnVCpj3tHp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqQrqdr0K-Cy"
      },
      "source": [
        "PyTorch Bi-LSTM RNN\n",
        "\n",
        "> we will define a custom Bidirectional LSTM using PyTorch in order to perform the Sentiment Analysis on the tweets.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL4HfoMNVr5m"
      },
      "source": [
        "Data preprocessing for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGZaoBjYWC2m"
      },
      "outputs": [],
      "source": [
        "#Data preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "#PyTorch LSTM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#Tokenization for LSTM\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "#Seed for reproducibility\n",
        "import random\n",
        "\n",
        "seed_value=42\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSPpabVGeJrv"
      },
      "source": [
        "Train - Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru3YcVvfeH4U"
      },
      "outputs": [],
      "source": [
        "X = rd['tweet_text']\n",
        "y = rd['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5xSz-3QeThM"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55sTWabFeZ-q"
      },
      "source": [
        "Train-Validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl4cW-IpectJ"
      },
      "outputs": [],
      "source": [
        "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XsIHbqbefyc"
      },
      "outputs": [],
      "source": [
        "# (unique, counts) = np.unique(y_train, return_counts=True)\n",
        "# np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSaoOcx4e2uI"
      },
      "source": [
        "Oversampling of training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JyzdKLMeifM"
      },
      "outputs": [],
      "source": [
        "# ros = RandomOverSampler()\n",
        "# X_train, y_train = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1));\n",
        "# train_os = pd.DataFrame(list(zip([x[0] for x in X_train], y_train)), columns = ['tweet_text', 'type']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB_47POAf0I1"
      },
      "outputs": [],
      "source": [
        "# X_train = train_os['tweet_text'].values\n",
        "# y_train = train_os['type'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a7vWH8hgF1A"
      },
      "outputs": [],
      "source": [
        "# (unique, counts) = np.unique(y_train, return_counts=True)\n",
        "# np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK-bI2UbVomi"
      },
      "outputs": [],
      "source": [
        "# def Tokenize(column, seq_len):\n",
        "#     ##Create vocabulary of words from column\n",
        "#     corpus = [word for text in column for word in text.split()]\n",
        "#     count_words = Counter(corpus)\n",
        "#     sorted_words = count_words.most_common()\n",
        "#     vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "#     ##Tokenize the columns text using the vocabulary\n",
        "#     text_int = []\n",
        "#     for text in column:\n",
        "#         r = [vocab_to_int[word] for word in text.split()]\n",
        "#         text_int.append(r)\n",
        "#     ##Add padding to tokens\n",
        "#     seq_len = int(seq_len)\n",
        "#     features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "#     for i, review in enumerate(text_int):\n",
        "#         if len(review) <= seq_len:\n",
        "#             zeros = list(np.zeros(seq_len - len(review)))\n",
        "#             new = zeros + review\n",
        "#         else:\n",
        "#             new = review[: seq_len]\n",
        "#         features[i, :] = np.array(new)\n",
        "\n",
        "#     return sorted_words, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Noaoe1BKWlYO"
      },
      "outputs": [],
      "source": [
        "# max_len = np.max(rd['text_len'])\n",
        "# max_len "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P3DOGUrWPjY"
      },
      "outputs": [],
      "source": [
        "# vocabulary, tokenized_column = Tokenize(rd[\"tweet_text\"], max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFRc2halcOww"
      },
      "outputs": [],
      "source": [
        "# rd[\"tweet_text\"].iloc[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3CQUtXcUma"
      },
      "outputs": [],
      "source": [
        "# tokenized_column[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_YWq4HqcWFj"
      },
      "outputs": [],
      "source": [
        "# keys = []\n",
        "# values = []\n",
        "# for key, value in vocabulary[:20]:\n",
        "#     keys.append(key)\n",
        "#     values.append(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E7cD_APcZbB"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(15, 5))\n",
        "# ax = sns.barplot(x=keys, y=values, palette='mako')\n",
        "# plt.title('Top 20 most common words', size=25)\n",
        "# ax.bar_label(ax.containers[0])\n",
        "# plt.ylabel(\"Words count\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsZKX9sEdaWP"
      },
      "outputs": [],
      "source": [
        "# Word2vec_train_data = list(map(lambda x: x.split(), X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWllAYR6gKGT"
      },
      "outputs": [],
      "source": [
        "# EMBEDDING_DIM = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN2QDcXugSbM"
      },
      "outputs": [],
      "source": [
        "# word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR_2N0VTgVxw"
      },
      "outputs": [],
      "source": [
        "# print(f\"Vocabulary size: {len(vocabulary) + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36OnTKhfhCNR"
      },
      "outputs": [],
      "source": [
        "# VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo-plVbOgboq"
      },
      "outputs": [],
      "source": [
        "# #define empty embedding matrix\n",
        "# embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "    \n",
        "# #fill the embedding matrix with the pre trained values from word2vec\n",
        "# #    corresponding to word (string), token (number associated to the word)\n",
        "# for word, token in vocabulary:\n",
        "#     if word2vec_model.wv.__contains__(word):\n",
        "#         embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "# print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71opImLQhcQS"
      },
      "source": [
        "Train - Validation - Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqUxJ3mnhEGL"
      },
      "outputs": [],
      "source": [
        "# X = tokenized_column\n",
        "# y = rd['type'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ptT0Xihi-H"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wENzB0OXhlTS"
      },
      "outputs": [],
      "source": [
        "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyDgyYhIhnML"
      },
      "outputs": [],
      "source": [
        "# (unique, counts) = np.unique(y_train, return_counts=True)\n",
        "# np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oUi094ahqLw"
      },
      "outputs": [],
      "source": [
        "# ros = RandomOverSampler()\n",
        "# X_train_os, y_train_os = ros.fit_resample(np.array(X_train),np.array(y_train));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lk503xxhs13"
      },
      "outputs": [],
      "source": [
        "# (unique, counts) = np.unique(y_train_os, return_counts=True)\n",
        "# np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsJvPoUghzSD"
      },
      "source": [
        "PyTorch datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERBptMjzv-hv"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch.utils.data import TensorDataset\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# y_train_encoded = le.fit_transform(y_train_os)\n",
        "# y_test_encoded = le.fit_transform(y_test)\n",
        "# y_valid_encoded = le.fit_transform(y_valid)\n",
        "# # Convert NumPy arrays to PyTorch tensors\n",
        "# Xtr_tensor = torch.tensor(X_train_os, dtype=torch.int64)\n",
        "# Ytr_tensor = torch.tensor(y_train_encoded, dtype=torch.int64)\n",
        "# Xtt_tensor = torch.tensor(X_test, dtype=torch.int64)\n",
        "# Ytt_tensor = torch.tensor(y_test_encoded, dtype=torch.int64)\n",
        "# Xv_tensor = torch.tensor(X_valid, dtype=torch.int64)\n",
        "# Yv_tensor = torch.tensor(y_valid_encoded, dtype=torch.int64)\n",
        "# # Create a TensorDataset from tensors\n",
        "# dataset_Xtr = TensorDataset(Xtr_tensor,Ytr_tensor)\n",
        "# dataset_Xtt = TensorDataset(Xtt_tensor,Ytt_tensor)\n",
        "# dataset_Xv = TensorDataset(Xv_tensor,Yv_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7raakG9ySPC"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# # Create a DataLoader from the TensorDataset\n",
        "# BATCH_SIZE = 32\n",
        "# dataloader_Xtr = DataLoader(dataset_Xtr, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# dataloader_Xtt = DataLoader(dataset_Xtt, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# dataloader_Xv = DataLoader(dataset_Xv, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRtPGGmNoRsl"
      },
      "source": [
        "Pytorch LSTM Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d5zq8xNoVHG"
      },
      "outputs": [],
      "source": [
        "# NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
        "# HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "# LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "# BATCH_SIZE=32\n",
        "# LR = 3e-4 #Learning rate\n",
        "# DROPOUT = 0.5 #LSTM Dropout\n",
        "# BIDIRECTIONAL = True #Boolean value to choose if to use a bidirectional LSTM or not\n",
        "# EPOCHS = 5 #Number of training epoch\n",
        "\n",
        "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkBBLb10ofOQ"
      },
      "outputs": [],
      "source": [
        "# class BiLSTM_Sentiment_Classifier(nn.Module):\n",
        "\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional,batch_size, dropout):\n",
        "#         super(BiLSTM_Sentiment_Classifier,self).__init__()\n",
        "        \n",
        "#         self.lstm_layers = lstm_layers\n",
        "#         self.num_directions = 2 if bidirectional else 1\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.num_classes = num_classes\n",
        "#         self.batch_size = batch_size\n",
        "        \n",
        "\n",
        "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "#         self.lstm = nn.LSTM(embedding_dim,\n",
        "#                             hidden_dim,\n",
        "#                             num_layers=lstm_layers,\n",
        "#                             dropout=dropout,\n",
        "#                             bidirectional=bidirectional,\n",
        "#                             batch_first=True)\n",
        "\n",
        "#         self.fc = nn.Linear(hidden_dim*self.num_directions, num_classes)\n",
        "#         self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "#     def forward(self, x, hidden):\n",
        "#         self.batch_size = x.size(0)\n",
        "#         ##EMBEDDING LAYER\n",
        "#         embedded = self.embedding(x)\n",
        "#         #LSTM LAYERS\n",
        "#         out, hidden = self.lstm(embedded, hidden)\n",
        "#         #Extract only the hidden state from the last LSTM cell\n",
        "#         out = out[:,-1,:]\n",
        "#         #FULLY CONNECTED LAYERS\n",
        "#         out = self.fc(out)\n",
        "#         out = self.softmax(out)\n",
        "\n",
        "#         return out, hidden\n",
        "\n",
        "#     def init_hidden(self, batch_size):\n",
        "#         #Initialization of the LSTM hidden and cell states\n",
        "#         h0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "#         c0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "#         hidden = (h0, c0)\n",
        "#         return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxa3Iz6BolWF"
      },
      "outputs": [],
      "source": [
        "# model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n",
        "# model = model.to(DEVICE)\n",
        "\n",
        "# #Initialize embedding with the previously defined embedding matrix\n",
        "# model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "# #Allow the embedding matrix to be fined tuned to better adapt to out dataset and get higher accuracy\n",
        "# model.embedding.weight.requires_grad=True\n",
        "\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUkeKNPaozBE"
      },
      "outputs": [],
      "source": [
        "# criterion = nn.NLLLoss()\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 5e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8FwSSEspNai"
      },
      "source": [
        "LSTM Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exGRvTeUpKS1"
      },
      "outputs": [],
      "source": [
        "# total_step = len(dataloader_Xtr)\n",
        "# total_step_val = len(dataloader_Xv)\n",
        "\n",
        "# early_stopping_patience = 4\n",
        "# early_stopping_counter = 0\n",
        "\n",
        "# valid_acc_max = 0 # Initialize best accuracy top 0\n",
        "\n",
        "# for e in range(EPOCHS):\n",
        "\n",
        "#     #lists to host the train and validation losses of every batch for each epoch\n",
        "#     train_loss, valid_loss  = [], []\n",
        "#     #lists to host the train and validation accuracy of every batch for each epoch\n",
        "#     train_acc, valid_acc  = [], []\n",
        "\n",
        "#     #lists to host the train and validation predictions of every batch for each epoch\n",
        "#     y_train_list, y_val_list = [], []\n",
        "\n",
        "#     #initalize number of total and correctly classified texts during training and validation\n",
        "#     correct, correct_val = 0, 0\n",
        "#     total, total_val = 0, 0\n",
        "#     running_loss, running_loss_val = 0, 0\n",
        "\n",
        "\n",
        "#     ####TRAINING LOOP####\n",
        "\n",
        "#     model.train()\n",
        "\n",
        "#     for inputs, labels in dataloader_Xtr:\n",
        "#         inputs, labels = inputs.to(DEVICE), labels.to(DEVICE) #load features and targets in device\n",
        "\n",
        "#         h = model.init_hidden(labels.size(0))\n",
        "\n",
        "#         model.zero_grad() #reset gradients \n",
        "\n",
        "#         output, h = model(inputs,h) #get output and hidden states from LSTM network\n",
        "        \n",
        "#         loss = criterion(output, labels)\n",
        "#         loss.backward()\n",
        "        \n",
        "#         running_loss += loss.item()\n",
        "        \n",
        "#         optimizer.step()\n",
        "\n",
        "#         y_pred_train = torch.argmax(output, dim=1) #get tensor of predicted values on the training set\n",
        "#         y_train_list.extend(y_pred_train.squeeze().tolist()) #transform tensor to list and the values to the list\n",
        "        \n",
        "#         correct += torch.sum(y_pred_train==labels).item() #count correctly classified texts per batch\n",
        "#         total += labels.size(0) #count total texts per batch\n",
        "\n",
        "#     train_loss.append(running_loss / total_step)\n",
        "#     train_acc.append(100 * correct / total)\n",
        "\n",
        "#     ####VALIDATION LOOP####\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "        \n",
        "#         model.eval()\n",
        "        \n",
        "#         for inputs, labels in dataloader_Xv:\n",
        "#             inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "#             val_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "#             output, val_h = model(inputs, val_h)\n",
        "\n",
        "#             val_loss = criterion(output, labels)\n",
        "#             running_loss_val += val_loss.item()\n",
        "\n",
        "#             y_pred_val = torch.argmax(output, dim=1)\n",
        "#             y_val_list.extend(y_pred_val.squeeze().tolist())\n",
        "\n",
        "#             correct_val += torch.sum(y_pred_val==labels).item()\n",
        "#             total_val += labels.size(0)\n",
        "\n",
        "#         valid_loss.append(running_loss_val / total_step_val)\n",
        "#         valid_acc.append(100 * correct_val / total_val)\n",
        "\n",
        "#     #Save model if validation accuracy increases\n",
        "#     if np.mean(valid_acc) >= valid_acc_max:\n",
        "#         torch.save(model.state_dict(), './state_dict.pt')\n",
        "#         print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n",
        "#         valid_acc_max = np.mean(valid_acc)\n",
        "#         early_stopping_counter=0 #reset counter if validation accuracy increases\n",
        "#     else:\n",
        "#         print(f'Epoch {e+1}:Validation accuracy did not increase')\n",
        "#         early_stopping_counter+=1 #increase counter if validation accuracy does not increase\n",
        "        \n",
        "#     if early_stopping_counter > early_stopping_patience:\n",
        "#         print('Early stopped at epoch :', e+1)\n",
        "#         break\n",
        "    \n",
        "#     print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n",
        "#     print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTxx8hkvrAGh"
      },
      "outputs": [],
      "source": [
        "# # Loading the best model\n",
        "# model.load_state_dict(torch.load('./state_dict.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkjw0SFVrFNp"
      },
      "source": [
        "LSTM Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B70CMHyyrITx"
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# y_pred_list = []\n",
        "# y_test_list = []\n",
        "# for inputs, labels in dataloader_Xtt:\n",
        "#     inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "#     test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "#     output, val_h = model(inputs, test_h)\n",
        "#     y_pred_test = torch.argmax(output, dim=1)\n",
        "#     y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "#     y_test_list.extend(labels.squeeze().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqgGI5YcRMD3"
      },
      "outputs": [],
      "source": [
        "# def conf_matrix(y, y_pred, title, labels):\n",
        "#     fig, ax =plt.subplots(figsize=(15,15))\n",
        "#     ax=sns.heatmap(confusion_matrix(y, y_pred), annot=True, cmap=\"Purples\", fmt='g', cbar=False, annot_kws={\"size\":30})\n",
        "#     plt.title(title, fontsize=25)\n",
        "#     ax.xaxis.set_ticklabels(labels, fontsize=16) \n",
        "#     ax.yaxis.set_ticklabels(labels, fontsize=14.5)\n",
        "#     ax.set_ylabel('Test', fontsize=25)\n",
        "#     ax.set_xlabel('Predicted', fontsize=25)\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tcu0bgnQ4J_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# conf_matrix(y_test_list, y_pred_list, 'PyTorch Bi-LSTM Sentiment Analysis\\nConfusion Matrix', ['NoTCyberbullying', 'Sexism', 'Religion', 'Age', 'Racism'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnK0G8G6uo8Y"
      },
      "outputs": [],
      "source": [
        "# print('Classification Report for Bi-LSTM:\\n', classification_report(y_test_list, y_pred_list, target_names=['NoTCyberbullying', 'Sexism', 'Religion', 'Age', 'Racism']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEQE68k3UFms"
      },
      "source": [
        "BERT "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js9JM0ruSCLZ",
        "outputId": "0d460ece-559d-4702-e231-9c0478bfe649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn-tVR9tw1aq"
      },
      "outputs": [],
      "source": [
        "#Transformers library for BERT\n",
        "import transformers\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Seed for reproducibility\n",
        "import random\n",
        "\n",
        "seed_value=42\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O-MHZQGwSOS"
      },
      "outputs": [],
      "source": [
        "X = rd['tweet_text'].values\n",
        "y = rd['type'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLbA8xqNwsLN"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Aro8tMGxpkk"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0aSa6B6xsi9"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train_os, y_train_os = ros.fit_resample(np.array(X_train).reshape(-1,1),np.array(y_train).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50rh4okwxvlp"
      },
      "outputs": [],
      "source": [
        "X_train_os = X_train_os.flatten()\n",
        "y_train_os = y_train_os.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l9gjuFdxyIg",
        "outputId": "81b9c4ca-9c73-4ea8-bef3-de6f0303ead0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0, 5698],\n",
              "       [   1, 5698],\n",
              "       [   2, 5698],\n",
              "       [   3, 5698],\n",
              "       [   4, 5698]])"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train_os, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHGylTsQx5RE"
      },
      "source": [
        "BERT Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMnw6k7tx0cP"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUsQyEjRyCk9"
      },
      "outputs": [],
      "source": [
        "def bert_tokenizer(data):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sent in data:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
        "            max_length=MAX_LEN,             # Choose max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length \n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3_gWVShyJjx",
        "outputId": "a0124249-8334-455d-86cc-cddc6e011ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length:  77\n"
          ]
        }
      ],
      "source": [
        "# Tokenize train tweets\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in X_train]\n",
        "\n",
        "# Find the longest tokenized tweet\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85TsMdizyWMi"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej3eqC5MyiHU",
        "outputId": "cb4d3d1f-3a63-4b61-d70c-2ed49e120eb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_inputs, train_masks = bert_tokenizer(X_train_os)\n",
        "val_inputs, val_masks = bert_tokenizer(X_valid)\n",
        "test_inputs, test_masks = bert_tokenizer(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9exVrGbyodo"
      },
      "outputs": [],
      "source": [
        "# Convert target columns to pytorch tensors format\n",
        "train_labels = torch.from_numpy(y_train_os)\n",
        "val_labels = torch.from_numpy(y_valid)\n",
        "test_labels = torch.from_numpy(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlAm92S-zgcU"
      },
      "source": [
        "Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N09262wEzZaA"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YELvFt2pzprT"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt7zbAjHz2U7"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obHIgHaNz57a"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our test set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4thAUH9L0CW-"
      },
      "source": [
        "BERT Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJiUUZRKz9P9"
      },
      "outputs": [],
      "source": [
        "class Bert_Classifier(nn.Module):\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        super(Bert_Classifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of the classifier, and number of labels\n",
        "        n_input = 768\n",
        "        n_hidden = 50\n",
        "        n_output = 5\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Add dense layers to perform the classification\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(n_input,  n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden, n_output)\n",
        "        )\n",
        "        # Add possibility to freeze the BERT model\n",
        "        # to avoid fine tuning BERT params (usually leads to worse results)\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Feed input data to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKw4lPvT0aZ6"
      },
      "outputs": [],
      "source": [
        "def initialize_model(epochs=4):\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = Bert_Classifier(freeze_bert=False)\n",
        "    \n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # learning rate, set to default value\n",
        "                      eps=1e-8    # decay, set to default value\n",
        "                      )\n",
        "    \n",
        "    ### Set up learning rate scheduler ###\n",
        "\n",
        "    # Calculate total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Defint the scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyx_OtQ10hBV"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EPOCHS=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt6lZZTr0jsr",
        "outputId": "aebf3a3a-2caa-4e42-da14-cc9242a1267f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9uALOh71Kse"
      },
      "source": [
        "BERT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuOZCQ8E0nR_"
      },
      "outputs": [],
      "source": [
        "# Define Cross entropy Loss function for the multiclass classification task\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def bert_train(model, train_dataloader, val_dataloader=None, epochs=1, evaluation=False):\n",
        "\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        print(\"-\"*10)\n",
        "        print(\"Epoch : {}\".format(epoch_i+1))\n",
        "        print(\"-\"*10)\n",
        "        print(\"-\"*38)\n",
        "        print(f\"{'BATCH NO.':^7} | {'TRAIN LOSS':^12} | {'ELAPSED (s)':^9}\")\n",
        "        print(\"-\"*38)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "        \n",
        "        ###TRAINING###\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            \n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass and get logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update model parameters:\n",
        "            # fine tune BERT params and train additional dense layers\n",
        "            optimizer.step()\n",
        "            # update learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 100 batches\n",
        "            if (step % 100 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "                \n",
        "                print(f\"{step:^9} | {batch_loss / batch_counts:^12.6f} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        ###EVALUATION###\n",
        "        \n",
        "        # Put the model into the evaluation mode\n",
        "        model.eval()\n",
        "        \n",
        "        # Define empty lists to host accuracy and validation for each batch\n",
        "        val_accuracy = []\n",
        "        val_loss = []\n",
        "\n",
        "        for batch in val_dataloader:\n",
        "            batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(device) for t in batch)\n",
        "            \n",
        "            # We do not want to update the params during the evaluation,\n",
        "            # So we specify that we dont want to compute the gradients of the tensors\n",
        "            # by calling the torch.no_grad() method\n",
        "            with torch.no_grad():\n",
        "                logits = model(batch_input_ids, batch_attention_mask)\n",
        "\n",
        "            loss = loss_fn(logits, batch_labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            # Get the predictions starting from the logits (get index of highest logit)\n",
        "            preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "            # Calculate the validation accuracy \n",
        "            accuracy = (preds == batch_labels).cpu().numpy().mean() * 100\n",
        "            val_accuracy.append(accuracy)\n",
        "\n",
        "        # Compute the average accuracy and loss over the validation set\n",
        "        val_loss = np.mean(val_loss)\n",
        "        val_accuracy = np.mean(val_accuracy)\n",
        "        \n",
        "        # Print performance over the entire training data\n",
        "        time_elapsed = time.time() - t0_epoch\n",
        "        print(\"-\"*61)\n",
        "        print(f\"{'AVG TRAIN LOSS':^12} | {'VAL LOSS':^10} | {'VAL ACCURACY (%)':^9} | {'ELAPSED (s)':^9}\")\n",
        "        print(\"-\"*61)\n",
        "        print(f\"{avg_train_loss:^14.6f} | {val_loss:^10.6f} | {val_accuracy:^17.2f} | {time_elapsed:^9.2f}\")\n",
        "        print(\"-\"*61)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O17kZv_p1ZXu",
        "outputId": "2715ba43-df3f-4481-e8fb-5ffed54a4930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            "----------\n",
            "Epoch : 1\n",
            "----------\n",
            "--------------------------------------\n",
            "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
            "--------------------------------------\n",
            "   100    |   0.661241   |  2314.06 \n",
            "   200    |   0.299919   |  2212.20 \n",
            "   300    |   0.256707   |  2218.87 \n",
            "   400    |   0.228211   |  2218.81 \n",
            "   500    |   0.220976   |  2207.50 \n",
            "   600    |   0.197645   |  2194.91 \n",
            "   700    |   0.211520   |  2206.83 \n",
            "   800    |   0.188363   |  2199.19 \n",
            "   890    |   0.180124   |  1995.62 \n",
            "-------------------------------------------------------------\n",
            "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
            "-------------------------------------------------------------\n",
            "   0.273098    |  0.196382  |       93.64       | 20436.96 \n",
            "-------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "bert_train(bert_classifier, train_dataloader, val_dataloader, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ROzDKsqrfgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e9818fe8-a617-4811-ea05-e57179a53a0c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-68782b704f0b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mnb' is not defined"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "pickle.dump(mnb,open('model.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqflKV7U1fqH"
      },
      "outputs": [],
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \n",
        "    # Define empty list to host the predictions\n",
        "    preds_list = []\n",
        "    \n",
        "    # Text input to classify\n",
        "    text = \"This is a hate speech comment\"\n",
        "\n",
        "    # Tokenize text input\n",
        "    input_ids, attention_masks = bert_tokenizer([text])\n",
        "\n",
        "    # Put the model into evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    for batch in test_dataloader:\n",
        "        batch_input_ids, batch_attention_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "        \n",
        "        # Avoid gradient calculation of tensors by using \"no_grad()\" method\n",
        "        with torch.no_grad():\n",
        "            logit = model(batch_input_ids, batch_attention_mask)\n",
        "        \n",
        "        # Get index of highest logit\n",
        "        pred = torch.argmax(logit,dim=1).cpu().numpy()\n",
        "        # Append predicted class to list\n",
        "        preds_list.extend(pred)\n",
        "\n",
        "    return preds_list\n",
        "    # Print predicted class \n",
        "    if pred == 0:\n",
        "      print(\"The text belongs to class 0: non-hate speech\")\n",
        "    else:\n",
        "      print(\"The text belongs to class 1: hate speech\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}